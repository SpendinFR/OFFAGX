{
  "desc_type": "module_emit",
  "name": "graal_multi_view_consensus",
  "code": "import os, json, time, hashlib\\nBASE = os.path.join('mem','graal')\\nFINAL = os.path.join(BASE,'final_form.json')\\nPERT = os.path.join(BASE,'perturbations.log')\\nCONS = os.path.join(BASE,'consensus.log')\\n\\ndef _dig(x):\\n    return hashlib.sha1(json.dumps(x,sort_keys=True,ensure_ascii=False).encode('utf-8')).hexdigest()[:12]\\n\\ndef _score_self(h):\\n    # aide le noyau Ã  se maintenir\\n    dt = h.get('desc_type') or h.get('kind') or ''\\n    bonus = 0\\n    if 'engine' in json.dumps(h,ensure_ascii=False): bonus += 3\\n    if 'generator' in json.dumps(h,ensure_ascii=False): bonus += 2\\n    return 5 + bonus\\n\\ndef _score_research(h):\\n    txt = json.dumps(h,ensure_ascii=False)\\n    sc = 0\\n    for k in ('math','research','open','conjecture','workflow'):\\n        if k in txt: sc += 2\\n    return sc\\n\\ndef _score_struct(h):\\n    # on aime les formes propres, peu de bruit, avec horodatage\\n    sc = 0\\n    if 'ts' in h: sc += 1\\n    if 'origin' in h: sc += 1\\n    if len(h.keys()) < 12: sc += 2\\n    return sc\\n\\ndef run(ctx=None):\\n    cands = []\\n    if os.path.exists(FINAL):\\n        with open(FINAL,'r',encoding='utf-8') as f: cands.append(json.load(f))\\n    # on relit juste les dernieres perturbations (pas besoin de tout)\\n    if os.path.exists(PERT):\\n        with open(PERT,'r',encoding='utf-8') as f: lines = f.readlines()[-5:]\\n        # ces lignes ne contiennent pas les variantes elles-memes, donc on se contente de ce qui est dans le pool via ctx\\n    # si le runtime nous a passe les streams, on va piocher les hypotheses dedans\\n    streams = (ctx or {}).get('streams') or []\\n    for s in streams:\\n        # on ne peut pas relire le contenu ici, mais on peut detecter son nom -> on laissera le noyau les remonter\\n        pass\\n    # donc on s'attend a ce que le noyau nous appelle AVEC les hypotheses deja promues dans PROMOTED_DESCS\\n    # pour rester generique, on fabrique juste une sortie de consensus\\n    scored = []\\n    for h in cands:\\n        ds = _dig(h)\\n        s1 = _score_self(h)\\n        s2 = _score_research(h)\\n        s3 = _score_struct(h)\\n        agree = (1 if s1>=s2 else 0) + (1 if s1>=s3 else 0) + (1 if s2>=s3 else 0)\\n        scored.append({'digest':ds,'h':h,'self':s1,'research':s2,'struct':s3,'agree':agree})\\n    scored.sort(key=lambda x: (x['agree'], x['self']+x['research']+x['struct']), reverse=True)\\n    best = scored[0] if scored else None\\n    os.makedirs(BASE, exist_ok=True)\\n    if best:\\n        with open(CONS,'a',encoding='utf-8') as f: f.write(json.dumps(best,ensure_ascii=False)+'\\\\n')\\n        return {\\n            'desc_type':'graal_consensus',\\n            'digest': best['digest'],\\n            'views': {\\n                'self': best['self'],\\n                'research': best['research'],\\n                'struct': best['struct']\\n            },\\n            'agree': best['agree'],\\n            'hypothesis': best['h'],\\n        }\\n    return {'desc_type':'graal_consensus_empty'}"
}
