{
  "desc_type": "module_emit",
  "name": "skill_requirement_llm_worker",
  "code": "import os, json, time, subprocess, hashlib\nPROMPT = \"\"\"Tu es un planificateur de compétences pour un agent autonome.\\nRéponds en JSON STRICT avec :\\n- desc_type: 'skill_build_plan'\\n- skill_id\\n- deps: liste de env:/lib:/os:/skill:\\n- steps: liste d'étapes parmi ensure_deps / gen_skill / test_skill\\nTâche : {task}\\n\"\"\"\n\ndef _ollama(txt: str) -> str:\n    try:\n        p = subprocess.Popen(['ollama', 'run', 'qwen3'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        out, err = p.communicate(input=txt.encode('utf-8'), timeout=60)\n        return out.decode('utf-8', errors='ignore')\n    except Exception as e:\n        return f\"LLM_ERROR::{e}\"\n\n\ndef _force_json(txt: str, task: str):\n    try:\n        return json.loads(txt)\n    except Exception:\n        try:\n            fixed = txt.replace(\"'\", '\"')\n            return json.loads(fixed)\n        except Exception:\n            sid = 'skill_' + hashlib.sha1(task.encode('utf-8')).hexdigest()[:10]\n            return {\n                'desc_type': 'skill_build_plan',\n                'skill_id': sid,\n                'task_text': task,\n                'deps': ['env:python'],\n                'steps': [\n                    {'step': 'ensure_deps', 'deps': ['env:python']},\n                    {'step': 'gen_skill', 'skill_id': sid, 'task_text': task}\n                ]\n            }\n\n\ndef run(ctx=None):\n    ctx = ctx or {}\n    if ctx.get('desc_type') != 'skill_req_llm_request':\n        return {'desc_type': 'skill_req_llm_ignore', 'ts': time.time()}\n    task = ctx.get('task_text') or ''\n    raw = _ollama(PROMPT.format(task=task))\n    plan = _force_json(raw, task)\n    plan['ts'] = time.time()\n    plan['source'] = 'llm'\n    return plan\n"
}
